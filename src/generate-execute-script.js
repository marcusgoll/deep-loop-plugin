#!/usr/bin/env node

/**
 * Generate Execute Script
 *
 * Creates a bash script for concurrent task queue processing.
 * N workers claim and execute tasks from .deep/tasks.md in parallel.
 * Each worker invokes `claude -p` for ONE task, then loops for next.
 *
 * Usage: node generate-execute-script.js <workers> <cwd>
 */

import fs from 'fs';
import path from 'path';

/**
 * Generate execute.sh script for concurrent task workers
 * @param {Object} options
 * @param {number} options.workers Number of concurrent workers
 * @param {string} options.cwd Working directory
 * @returns {string} Path to generated script
 */
export function generateExecuteScript(options) {
  const {
    workers = 3,
    cwd = process.cwd()
  } = options;

  const scriptPath = path.join(cwd, '.deep', 'execute.sh');
  const bashCwd = cwd.replace(/\\/g, '/');

  const workerPrompt = `You are a deep-execute worker processing ONE task from the queue.

INSTRUCTIONS:
1. Read .deep/tasks.md and .deep/claims.json
2. Find the first unclaimed task (## [ ] task-XXX) in priority order (high > medium > low)
   - Skip tasks claimed in claims.json (unless claim older than 30 min)
   - Skip tasks with Attempts >= 3
   - Skip tasks with Status: git-blocked (unless you can verify conflict resolved)
3. If NO eligible tasks: output exactly QUEUE_EMPTY and stop
4. Claim the task: update claims.json with your worker ID and 30-min expiry
5. Execute the task through all phases:

   PLAN: Create mini-plan, identify files to modify
   BUILD: Implement changes, write tests, run code-simplifier via Task tool (subagent_type: deep-loop:code-simplifier, model: haiku)
   REVIEW: Run tests (npm test or pytest), lint (npm run lint), typecheck (npx tsc --noEmit)
   FIX: If issues found, fix them (max 3 iterations, then TASK_FAILED)
   SHIP: git add + commit with message "[deep] implement: {task title}" + push with rebase retry (max 3 attempts)

6. On success:
   - Remove task from tasks.md
   - Append to completed-tasks.md with commit SHA, timestamp, session, files changed
   - Remove claim from claims.json
   - Output: TASK_COMPLETE:{task-id}:{commit-sha}

7. On failure (after 3 FIX iterations):
   - Increment Attempts in tasks.md, add Last Attempt line
   - Release claim from claims.json
   - Output: TASK_FAILED:{task-id}:{reason}

8. On git conflict (push rejected, rebase has conflicts):
   - Create recovery branch: deep-recovery/{task-id}-{worker-id}
   - Add to git-conflicts.json
   - Mark task as git-blocked in tasks.md (do NOT increment Attempts)
   - Release claim, reset to clean state
   - Output: TASK_GIT_BLOCKED:{task-id}:{conflicting-files}

WORKER_ID will be set as environment variable.
Work autonomously. Do NOT ask for confirmation. Execute the full loop for ONE task then exit.`;

  // Escape prompt for bash heredoc
  const escapedPrompt = workerPrompt.replace(/\\/g, '\\\\').replace(/\$/g, '\\$');

  const script = `#!/bin/bash
# Generated by /deep execute - Concurrent Worker Mode
# Workers: ${workers}
# CWD: ${bashCwd}
# Generated: ${new Date().toISOString()}

# No set -e: workers handle errors explicitly to avoid silent deaths
set -uo pipefail

CWD="${bashCwd}"
DEEP_DIR="$CWD/.deep"
WORKERS=${workers}
MAX_LOOPS_PER_WORKER=50
PIDS=()

# Telegram notification
notify() {
  local status="\$1"
  local message="\$2"
  if [[ -n "\${TELEGRAM_BOT_TOKEN:-}" && -n "\${TELEGRAM_CHAT_ID:-}" ]]; then
    curl -s -X POST "https://api.telegram.org/bot\$TELEGRAM_BOT_TOKEN/sendMessage" \\
      -d chat_id="\$TELEGRAM_CHAT_ID" \\
      -d text="⚡ Deep Execute [\$status]: \$message" \\
      -d parse_mode="Markdown" > /dev/null 2>&1 || true
  fi
}

cd "$CWD" || { echo "Failed to cd to $CWD"; exit 1; }

# Verify claude CLI
if ! command -v claude &> /dev/null; then
  echo "Error: Claude Code CLI not found"
  exit 1
fi

# Ensure .deep directory exists
mkdir -p "$DEEP_DIR"
[ -f "$DEEP_DIR/claims.json" ] || echo '{}' > "$DEEP_DIR/claims.json"
[ -f "$DEEP_DIR/completed-tasks.md" ] || touch "$DEEP_DIR/completed-tasks.md"
[ -f "$DEEP_DIR/git-conflicts.json" ] || echo '{}' > "$DEEP_DIR/git-conflicts.json"

echo "=========================================="
echo "  DEEP EXECUTE - CONCURRENT WORKERS"
echo "=========================================="
echo ""
echo "Workers: $WORKERS"
echo "Queue: $DEEP_DIR/tasks.md"
echo "Logs: $DEEP_DIR/worker-*.log"
echo "Max loops/worker: \$MAX_LOOPS_PER_WORKER"
echo ""
echo "Force exit: touch $DEEP_DIR/FORCE_EXECUTE_EXIT"
echo ""

notify "STARTED" "Launching $WORKERS concurrent workers..."

START_TIME=\$(date +%s)

# Worker function - runs in subshell, errors do NOT kill master
run_worker() {
  local WORKER_NUM=\$1
  local WORKER_ID="w\${WORKER_NUM}-\$RANDOM\$RANDOM"
  local LOG="$DEEP_DIR/worker-\${WORKER_NUM}.log"
  local TASKS_DONE=0
  local TASKS_FAILED=0
  local TASKS_BLOCKED=0
  local LOOPS=0
  local CONSECUTIVE_UNEXPECTED=0

  # Ensure log file exists
  touch "\$LOG" 2>/dev/null || true

  # Unset API key to force OAuth (Windows-compatible, no env -u)
  unset ANTHROPIC_API_KEY 2>/dev/null || true

  echo "[\$WORKER_ID] Worker \$WORKER_NUM started" >> "\$LOG" 2>/dev/null

  while true; do
    LOOPS=\$((LOOPS + 1))

    # Guard: max loops per worker
    if [[ \$LOOPS -gt \$MAX_LOOPS_PER_WORKER ]]; then
      echo "[\$WORKER_ID] Max loops (\$MAX_LOOPS_PER_WORKER) reached, stopping" >> "\$LOG" 2>/dev/null
      notify "WARN" "Worker \$WORKER_NUM hit max loops (\$MAX_LOOPS_PER_WORKER)"
      break
    fi

    # Check force exit
    if [[ -f "$DEEP_DIR/FORCE_EXECUTE_EXIT" ]]; then
      echo "[\$WORKER_ID] Force exit detected" >> "\$LOG" 2>/dev/null
      break
    fi

    echo "[\$WORKER_ID] Loop \$LOOPS: claiming next task..." >> "\$LOG" 2>/dev/null

    WORKER_PROMPT='${escapedPrompt}

ADDITIONAL CONTEXT:
- Your WORKER_ID is: '"\$WORKER_ID"'
- Working directory: ${bashCwd}
- IMPORTANT: When reading claims.json, if another worker claimed the same task between your read and write, pick a different task. Use file timestamps to detect stale reads.'

    # Stream output to log in real-time via tee, capture for result parsing
    OUTPUT=\$(claude -p "\$WORKER_PROMPT" \\
      --output-format text \\
      --allowedTools "Read,Edit,Write,Bash,Grep,Glob,Task,Skill" \\
      --dangerously-skip-permissions 2>&1 | tee -a "\$LOG" || true)

    # Parse result
    if echo "\$OUTPUT" | grep -q "QUEUE_EMPTY"; then
      echo "[\$WORKER_ID] Queue empty, stopping" >> "\$LOG" 2>/dev/null
      CONSECUTIVE_UNEXPECTED=0
      break
    elif echo "\$OUTPUT" | grep -q "TASK_COMPLETE"; then
      TASKS_DONE=\$((TASKS_DONE + 1))
      TASK_INFO=\$(echo "\$OUTPUT" | grep "TASK_COMPLETE" | tail -1)
      echo "[\$WORKER_ID] ✓ \$TASK_INFO" >> "\$LOG" 2>/dev/null
      CONSECUTIVE_UNEXPECTED=0
    elif echo "\$OUTPUT" | grep -q "TASK_FAILED"; then
      TASKS_FAILED=\$((TASKS_FAILED + 1))
      TASK_INFO=\$(echo "\$OUTPUT" | grep "TASK_FAILED" | tail -1)
      echo "[\$WORKER_ID] ✗ \$TASK_INFO" >> "\$LOG" 2>/dev/null
      CONSECUTIVE_UNEXPECTED=0
    elif echo "\$OUTPUT" | grep -q "TASK_GIT_BLOCKED"; then
      TASKS_BLOCKED=\$((TASKS_BLOCKED + 1))
      TASK_INFO=\$(echo "\$OUTPUT" | grep "TASK_GIT_BLOCKED" | tail -1)
      echo "[\$WORKER_ID] ⚠ \$TASK_INFO" >> "\$LOG" 2>/dev/null
      CONSECUTIVE_UNEXPECTED=0
    else
      CONSECUTIVE_UNEXPECTED=\$((CONSECUTIVE_UNEXPECTED + 1))
      echo "[\$WORKER_ID] No result token (streak: \$CONSECUTIVE_UNEXPECTED)" >> "\$LOG" 2>/dev/null

      # 3 consecutive unexpected outputs = something is wrong, bail
      if [[ \$CONSECUTIVE_UNEXPECTED -ge 3 ]]; then
        echo "[\$WORKER_ID] 3 consecutive failures, stopping" >> "\$LOG" 2>/dev/null
        notify "ERROR" "Worker \$WORKER_NUM stopped: 3 consecutive unexpected outputs"
        break
      fi
    fi

    # Brief pause before next claim
    sleep 1
  done

  echo "[\$WORKER_ID] Final: done=\$TASKS_DONE failed=\$TASKS_FAILED blocked=\$TASKS_BLOCKED" >> "\$LOG" 2>/dev/null

  # Write summary for aggregation
  echo "\$TASKS_DONE \$TASKS_FAILED \$TASKS_BLOCKED" > "$DEEP_DIR/worker-\${WORKER_NUM}.result" 2>/dev/null
}

# Launch workers with staggered starts
for i in \$(seq 1 $WORKERS); do
  run_worker \$i &
  PIDS+=(\$!)
  echo "Launched worker \$i (PID: \${PIDS[-1]})"
  if [[ \$i -lt $WORKERS ]]; then
    sleep 2  # Stagger to reduce claim contention
  fi
done

echo ""
echo "All $WORKERS workers launched. Waiting for completion..."
echo "Monitor: tail -f $DEEP_DIR/worker-*.log"
echo ""

# Wait for all workers
EXIT_CODE=0
for pid in "\${PIDS[@]}"; do
  wait \$pid || EXIT_CODE=1
done

END_TIME=\$(date +%s)
DURATION=\$(( END_TIME - START_TIME ))
MINUTES=\$(( DURATION / 60 ))
SECONDS_REM=\$(( DURATION % 60 ))

# Aggregate results (default 0 if worker crashed before writing)
TOTAL_DONE=0
TOTAL_FAILED=0
TOTAL_BLOCKED=0

for i in \$(seq 1 $WORKERS); do
  RESULT_FILE="$DEEP_DIR/worker-\${i}.result"
  if [[ -f "\$RESULT_FILE" ]]; then
    read D F B < "\$RESULT_FILE" 2>/dev/null || { D=0; F=0; B=0; }
    TOTAL_DONE=\$((TOTAL_DONE + \${D:-0}))
    TOTAL_FAILED=\$((TOTAL_FAILED + \${F:-0}))
    TOTAL_BLOCKED=\$((TOTAL_BLOCKED + \${B:-0}))
  else
    echo "Warning: worker \$i result missing (crashed?)"
  fi
done

echo ""
echo "=========================================="
echo "  DEEP EXECUTE COMPLETE"
echo "=========================================="
echo ""
echo "Duration: \${MINUTES}m \${SECONDS_REM}s"
echo "Completed: \$TOTAL_DONE"
echo "Failed: \$TOTAL_FAILED"
echo "Git-Blocked: \$TOTAL_BLOCKED"
echo ""

# Show completed tasks
if [[ -f "$DEEP_DIR/completed-tasks.md" ]]; then
  COMPLETED=\$(grep -c "^## \\[x\\]" "$DEEP_DIR/completed-tasks.md" 2>/dev/null || echo 0)
  echo "Total in completed-tasks.md: \$COMPLETED"
fi

# Show git-blocked tasks
if [[ -f "$DEEP_DIR/git-conflicts.json" ]] && [[ \$(wc -c < "$DEEP_DIR/git-conflicts.json") -gt 3 ]]; then
  echo ""
  echo "Git-blocked tasks (resolve manually):"
  echo "  git branch | grep deep-recovery/"
  echo "  See: $DEEP_DIR/git-conflicts.json"
fi

# Cleanup
rm -f $DEEP_DIR/worker-*.result
rm -f "$DEEP_DIR/FORCE_EXECUTE_EXIT" 2>/dev/null || true

SUMMARY="Done: \$TOTAL_DONE | Failed: \$TOTAL_FAILED | Blocked: \$TOTAL_BLOCKED | Time: \${MINUTES}m \${SECONDS_REM}s"
notify "COMPLETE" "✅ \$SUMMARY"

exit \$EXIT_CODE
`;

  // Ensure .deep directory exists
  const deepDir = path.join(cwd, '.deep');
  if (!fs.existsSync(deepDir)) {
    fs.mkdirSync(deepDir, { recursive: true });
  }

  fs.writeFileSync(scriptPath, script, { mode: 0o755 });
  return scriptPath;
}

/**
 * CLI entry point
 * Usage: node generate-execute-script.js <workers> <cwd>
 */
if (process.argv[1] && process.argv[1].endsWith('generate-execute-script.js')) {
  const args = process.argv.slice(2);

  if (args.length < 2) {
    console.error('Usage: generate-execute-script.js <workers> <cwd>');
    process.exit(1);
  }

  const workers = parseInt(args[0]) || 3;
  const cwd = args[1];

  try {
    const scriptPath = generateExecuteScript({ workers, cwd });
    console.log(`Generated: ${scriptPath}`);
  } catch (err) {
    console.error('Error generating script:', err.message);
    process.exit(1);
  }
}

export default generateExecuteScript;
